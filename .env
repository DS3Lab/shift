# REST API
REST_HOST=0.0.0.0
REST_NUM_WORKERS=1

# Celery
REDIS_BROKER=redis://redis:6379
REDIS_BACKEND=redis://redis:6379

# Redis connection
REDIS_HOST="redis"
REDIS_PORT=6379
REDIS_DB=0

# Postgres connection
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_DATABASE=postgres

# Celery names
WORKER_GENERAL_INFERENCE_JOB_NAME=main.run_inference
WORKER_GENERAL_CLASSIFIER_JOB_NAME=main.run_classifier
WORKER_GENERAL_TASK2VEC_JOB_NAME=main.run_task2vec
WORKER_GENERAL_FINETUNE_JOB_NAME=main.run_finetune
WORKER_TF1_INFERENCE_JOB_NAME=main.run_inference
WORKER_GENERAL_QUEUE_NAME=shift:queue_1
WORKER_TF1_QUEUE_NAME=shift:queue_2

# User input
INPUT_LOCATION=/user_input

# Results
RESULTS_LOCATION=/results

# Caching
CACHE_LOCATION=/home/xzyao/data/syscache/shift/cache
TFDS_LOCATION=/cache/TFDS_cache
TORCH_DATASET_LOCATION=/cache/torch_data_cache

## Directly used by TF Hub
TFHUB_CACHE_DIR=/cache/TF_hub_cache

## Directly used by HF Datasets
## Specifying the environment variable preferred to setting cache_dir and data_dir
## because it also handles storage of download scripts
## https://huggingface.co/docs/datasets/installation.html
HF_HOME=/cache/HF

## Directly used by HuggingFace Transformers
TRANSFORMERS_CACHE=/cache/HF_model_cache

## Directly used by Torch Hub
TORCH_HOME=/cache/torch_model_cache

# CPU jobs
MAX_CPU_JOBS=2

# Embeddings
TF_PREFETCH_SIZE=10
PT_PREFETCH_FACTOR=10
PT_NUM_WORKERS=3

# Result
RESULT_MAX_ROWS=100000
RESULT_MAX_VALUES=1000000000

# FINETUNE Models